# 设备/命令筛选的微调选择模型（后续考虑记录）

> 创建日期：2026-01-07  
> 状态：想法记录（暂不进入规划/实施）

## 1. 背景

当前项目中，“设备筛选 + 命令筛选”在多处会被频繁调用，本质是一个 **从候选集中做选择/排序（routing + rerank）** 的任务。它与“生成命令参数”不同：核心诉求是更高的 top-1 正确率、更强的指代/歧义处理，以及更稳定的结构化输出。

## 2. 微调模型主要用于做什么

微调后的模型建议定位为 **Selector / Reranker**（不负责生成复杂自然语言，不负责生成最终参数），主要覆盖两类子任务：

### 2.1 设备选择（Device Selector）

输入：用户指令 + 多轮上下文（最近提及设备/房间/类别等）+ 候选设备列表（Top-K 召回结果，包含 name/room/category/可用能力摘要等）。

输出：
- 目标设备的有序列表（可多选）与置信度；
- 需要澄清时给出“澄清意图”（例如返回 `need_clarification=true` 与若干候选）。

### 2.2 命令/能力选择（Command/Capability Selector）

输入：用户指令 + 已选设备 + 候选命令/能力列表（包含 capability_id、命令描述、参数形态的摘要等）。

输出：
- 最匹配的 `capability_id`/`command_id`（可多选）与置信度；
- 当存在多条命令相近或参数缺失时，输出“需要澄清/补参”的信号（而不是直接胡乱生成参数）。

## 3. 预期收益（为什么值得做）

### 3.1 准确率与鲁棒性

- **提高 top-1**：在同房间多设备、同类设备命名相近、口语化/别名、指代词（“它/那个”）场景下，微调模型能学习项目内的真实分布与偏好。
- **更可控的歧义处理**：通过显式输出 `need_clarification`，把“选择不确定”与“选择错误”区分开，减少误执行风险。

### 3.2 性能与成本

- **更低延迟/成本**：选择任务通常可以由更小的模型完成（甚至本地化），减少主模型参与次数与输入 token。
- **更稳定的结构化输出**：相比通用 LLM 的自由生成，微调模型可以对输出 schema 做强约束，降低解析失败与重试率。

### 3.3 可评估与可迭代

- 选择/排序任务天然适合离线评测（MRR、Top-1/Top-k、Calibration），比端到端生成更容易定位问题与回归。

## 4. 适用边界（建议不做什么）

- 不建议让该模型直接生成最终可执行参数；参数生成更适合保留给主模型或受约束的参数填充器（以保证完整性与安全）。
- 该模型更适合在“候选已召回”的前提下做精排/选择；召回仍应由规则/关键词/向量检索承担，以保证覆盖率。

## 5. 数据与训练形态（后续如果要做）

- 数据来源：线上/离线日志（用户输入、对话上下文、候选列表、最终被确认的 device_id 与 capability/command）、人工补标的歧义样本。
- 训练形态：
  - 排序（pairwise/listwise rerank）：学习在候选集合中把“正确项”排到前面；
  - 分类（multi-class over candidates）：候选集合内选择；
  - 置信度校准：用于触发澄清或回退策略。

## 6. 何时值得启动（触发条件）

- 线上出现稳定的“歧义/误选”痛点，且候选集合模式相对稳定（设备规模、命名、能力集合不会频繁剧变）。
- 有足够的可用数据（至少能覆盖主要类别与高频指令分布），并能建立离线评测集与回归机制。

